import argparse
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor
from sklearn.svm import SVR
from xgboost import XGBRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from data_loader import load_train_data, load_test_data
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt

# ========================== 1ï¸âƒ£ CHUYá»‚N Dá»® LIá»†U TIME-SERIES â†’ TABULAR ==========================

def extract_features(X, window_size=10):
    """
    Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u chuá»—i thá»i gian thÃ nh dáº¡ng báº£ng báº±ng cÃ¡ch tÃ­nh cÃ¡c Ä‘áº·c trÆ°ng thá»‘ng kÃª.
    """
    feature_list = []
    
    for i in range(window_size, X.shape[0]):  
        window = X[i-window_size:i]  # Láº¥y má»™t cá»­a sá»• dá»¯ liá»‡u
        
        # TÃ­nh toÃ¡n cÃ¡c Ä‘áº·c trÆ°ng thá»‘ng kÃª
        feature_vector = [
            np.mean(window, axis=0),  # GiÃ¡ trá»‹ trung bÃ¬nh
            np.std(window, axis=0),   # Äá»™ lá»‡ch chuáº©n
            np.min(window, axis=0),   # Min
            np.max(window, axis=0),   # Max
            np.median(window, axis=0) # Trung vá»‹
        ]
        
        # GhÃ©p táº¥t cáº£ Ä‘áº·c trÆ°ng thÃ nh má»™t vector
        feature_list.append(np.concatenate(feature_vector))
    
    return np.array(feature_list)

# ========================== 2ï¸âƒ£ HÃ€M CHá»ŒN MÃ” HÃŒNH ML ==========================

def get_ml_model(model_type):
    """
    Tráº£ vá» thuáº­t toÃ¡n ML Regression phÃ¹ há»£p.
    """
    if model_type == "SVM":
        return SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)
    elif model_type == "RF":
        return RandomForestRegressor(n_estimators=100, random_state=42)
    elif model_type == "AdaBoost":
        return AdaBoostRegressor(n_estimators=50, random_state=42)
    elif model_type == "XGBoost":
        return XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
    else:
        raise ValueError("Invalid model type. Choose from: SVM, RF, AdaBoost, XGBoost")

# ========================== 3ï¸âƒ£ HÃ€M HUáº¤N LUYá»†N MÃ” HÃŒNH ML ==========================

def train_ml_model(model_type, X_train, X_test, Y_test):
    """
    Huáº¥n luyá»‡n mÃ´ hÃ¬nh ML Regression vÃ  tÃ­nh toÃ¡n lá»—i tÃ¡i táº¡o.
    - Sá»­ dá»¥ng X_train Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh.
    - MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n chÃ­nh X_train Ä‘á»ƒ há»c cÃ¡ch tÃ¡i táº¡o dá»¯ liá»‡u bÃ¬nh thÆ°á»ng.
    """
    model = get_ml_model(model_type)

    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh (khÃ´ng cáº§n Y_train)
    print(f"\nğŸš€ Training {model_type} model...")
    model.fit(X_train, X_train.mean(axis=1))  # DÃ¹ng chÃ­nh X_train Ä‘á»ƒ há»c cÃ¡ch tÃ¡i táº¡o

    # Dá»± Ä‘oÃ¡n trÃªn táº­p kiá»ƒm tra
    y_pred = model.predict(X_test)

    # TÃ­nh toÃ¡n lá»—i tÃ¡i táº¡o (Reconstruction Error)
    reconstruction_error = ((X_test.mean(axis=1) - y_pred) ** 2)

    # ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
    mse = mean_squared_error(X_test.mean(axis=1), y_pred)
    r2 = r2_score(X_test.mean(axis=1), y_pred)

    print(f"\nğŸ“Š {model_type} - MSE: {mse:.4f}, R2 Score: {r2:.4f}")

    return model, reconstruction_error

# ========================== 4ï¸âƒ£ MAIN SCRIPT ==========================

if __name__ == "__main__":
    # Nháº­n tham sá»‘ tá»« dÃ²ng lá»‡nh
    parser = argparse.ArgumentParser()
    parser.add_argument("--ml", type=str, default="RF", help="Choose ML model: SVM, RF, AdaBoost, XGBoost")
    args = parser.parse_args()

    # Load dá»¯ liá»‡u tá»« repo GitHub
    dataset_name = "BATADAL"
    X_train, sensor_cols = load_train_data(dataset_name)  # X_train khÃ´ng cÃ³ nhÃ£n Y_train
    X_test, Y_test, _ = load_test_data(dataset_name)  # Táº­p kiá»ƒm tra cÃ³ nhÃ£n

    # Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u chuá»—i thá»i gian thÃ nh dáº¡ng báº£ng
    window_size = 10
    X_train_features = extract_features(X_train, window_size)
    X_test_features = extract_features(X_test, window_size)

    print("\nğŸ“Œ Dá»¯ liá»‡u sau khi chuyá»ƒn Ä‘á»•i:")
    print("ğŸ”¹ X_train_features shape:", X_train_features.shape)
    print("ğŸ”¹ X_test_features shape:", X_test_features.shape)

    # Chuáº©n hÃ³a dá»¯ liá»‡u
    scaler = StandardScaler()
    X_train_features = scaler.fit_transform(X_train_features)
    X_test_features = scaler.transform(X_test_features)

    # Náº¿u cÃ³ chá»n ML, thÃ¬ huáº¥n luyá»‡n ML
    if args.ml:
        model, reconstruction_error = train_ml_model(args.ml, X_train_features, X_test_features, Y_test)

        # XÃ¡c Ä‘á»‹nh ngÆ°á»¡ng báº¥t thÆ°á»ng (95th percentile)
        threshold = np.percentile(reconstruction_error, 95)
        anomalies = (reconstruction_error > threshold).astype(int)

        # ========================== 5ï¸âƒ£ ÄÃNH GIÃ Káº¾T QUáº¢ ==========================

        print("\nğŸ“Œ Classification Report:")
        print(classification_report(Y_test, anomalies))

        print(f"\nâœ… Sá»‘ Ä‘iá»ƒm báº¥t thÆ°á»ng phÃ¡t hiá»‡n Ä‘Æ°á»£c: {sum(anomalies)} / {len(Y_test)}")
        print(f"ğŸ“Š NgÆ°á»¡ng báº¥t thÆ°á»ng: {threshold:.4f}")

        # ========================== 6ï¸âƒ£ TRá»°C QUAN HÃ“A ==========================

        plt.figure(figsize=(8, 5))
        plt.hist(reconstruction_error, bins=50, color='blue', alpha=0.7)
        plt.axvline(threshold, color='red', linestyle='dashed', label='Threshold')
        plt.title("Lá»—i tÃ¡i táº¡o (Reconstruction Error)")
        plt.xlabel("Error")
        plt.ylabel("Frequency")
        plt.legend()
        plt.show()
